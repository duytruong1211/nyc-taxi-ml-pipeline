# ğŸ—½ NYC Taxi ML Pipeline

A full-stack machine learning pipeline to predict NYC taxi trip duration.

**Designed for:** clarity, reproducibility, and real-world ML infra readiness â€” with lean setup for cloning.

---
## Project Summary

This is a solo project built as a demonstration of end-to-end ML workflow using NYC Taxi data.  
All data processing, modeling, and documentation were done by me.

Data Source: NYC Taxi Dataset (https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)  
Weather Data: Open-Meteo API (https://open-meteo.com)  


## ğŸ“˜ Reports

- ğŸ—’ï¸ [Notion Summary Report](https://bitter-aster-788.notion.site/NYC-Taxi-ETA-Forecasting-Modeling-Meets-Real-World-Chaos-2248b64123bf805991cae210535ab3c7) *(stakeholder view â€“ business insights)*
- ğŸ““ [Notebook Spark Walkthrough](spark_full/spark_eta_model.ipynb) *(Spark ML version â€“ deep dive)*


---

## ğŸ§­ Project Evolution

> **Prototyped in Spark. Delivered in pandas.**

The project began with a full **Spark-based workflow** for processing large-scale NYC TLC data, using:

- ğŸ”¹ Spark for prototyping data transformations and rolling aggregations  
- ğŸ”¹ dbt for SQL-style modeling  
- ğŸ”¹ Dagster for orchestration (optional)

However, for simplicity, speed, and **ease of cloning**, we **ported the full pipeline to Python + pandas**.

### âœ… Why pandas for final version?

- âš¡ Lightweight: no Spark setup or cluster needed
- ğŸ’» Local-friendly: works out-of-the-box via `python main.py`
- ğŸ” Same logic: All Spark SQL logic reimplemented using pandas
- ğŸ“¦ Portable: Easy to fork, run, and adapt


Both versions are maintained:

- **`/spark_full/`** folder â€” full Spark/dbt version
- **Root folder** â€” lean pandas version for reproducibility and demo

## ğŸš§ Prerequisites

Before you run this project, make sure you have the following installed:

## ğŸ³ Docker

- [Install Docker Desktop](https://www.docker.com/products/docker-desktop/)  
  (Required for building and running containers)

You can test Docker is working with:

```bash
docker --version
docker-compose --version
```
## ğŸš€ Quickstart
```bash
### âœ… Clone the repo
git clone https://github.com/duytruong1211/nyc-taxi-ml-pipeline.git
cd nyc-taxi-ml-pipeline

### ğŸ”¨ One-time build (first-time users)
make build

### ğŸ§ª Run test pipeline (quick demo)
make test
### â†’ Ingests Janâ€“Apr 2024
### â†’ Trains + logs model for April 2024

### ğŸ› ï¸ Run full historical pipeline (bulk mode)
make bulk
### â†’ Ingests + processes all 2023â€“2024 trips
### â†’ Builds rolling features per PU/DO pair
### â†’ Trains + logs models per month

### ğŸ“… Ingest new month (incremental mode)
make incremental YEAR=2025 MONTH=1
### â†’ Ingests new trip data
### â†’ Updates zone-pair aggregates
### â†’ Retrains model on latest month

### ğŸ“Š Launch MLflow UI to track model runs
make ui
### â†’ Open http://localhost:5001 in browser

### ğŸ§¼ Cleanup (optional)
make stop            # Stop all containers
make clean           # Stop + remove volumes
make clean-orphans   # Delete leftover run containers
```
---

## ğŸ“‚ Project Structure

```text
nyc-taxi-ml-pipeline/
â”œâ”€â”€ data/                            # Raw and processed datasets
â”‚   â”œâ”€â”€ bronze/                      # Raw ingested files
â”‚   â”œâ”€â”€ silver/                      # Cleaned + enriched datasets
â”‚   â””â”€â”€ gold/                        # Final ML-ready feature tables
â”‚
â”œâ”€â”€ etl/                             # Scripts for data ingestion and transformation 
â”‚   â”œâ”€â”€ bronze.py                    # Data ingestion
â”‚   â””â”€â”€ silver.py                    # Ligh transform, downsizing 
â”‚   â””â”€â”€ gold.py                      # Enriched, ultilized DUCKDB
â”‚
â”œâ”€â”€ models/                          # Scripts for model building
â”‚   â”œâ”€â”€ configs.py                   # Constant variables, Tuned hyperparameters
â”‚   â””â”€â”€ evaluates.py                 # Metrics, Feature Importances
â”‚   â””â”€â”€ prepare.py                   # Train test split, Encoding
â”‚
â”œâ”€â”€ pipeline/                        # Combine everything together
â”‚   â”œâ”€â”€ ml_pipeline.py               # Build Model, save results to MLFLow
â”‚   â”œâ”€â”€ pipeline.py                  # Bronze -> Silver -> Gold
â”‚
â”œâ”€â”€ spark_full/                      # Spark artifact, dbt, dagster
â”‚
â”œâ”€â”€ main.py                          # Pipeline orchestration entry point
â”œâ”€â”€ Dockerfile                       # Reproducible container setup for pipeline
â””â”€â”€ README.md                        # Project overview and usage guide
```

---

## ğŸ” Model Overview

After running the pipeline, launch MLflow UI:

```bash
mlflow ui
```
You will see a dashboard like this. CLick on the Columns tab to track metrics( MAE, R2, feature gains/weight)
![MLflow Dashboard](utils/mlflow_output.png)


---

## ğŸ§± Feature Store Summary

- **Temporal**  
  `pickup_hour`, `is_rush_hour_morning`, `is_weekend`

- **Calendar**  
  `is_holiday`, `is_near_holiday`, `is_payroll_window`

- **Zone & Ride Info**  
  `is_same_zone`, `is_airport_pu_trip`, `passenger_count`

- **Weather** *(by borough & hour)*  
  `temperature`, `precipitation`, `cloudcover`

- **Rolling Aggregates** *(PU-DO pairs)*  
  `avg_duration_min_3mo`, `avg_fare_12mo`, `trip_count_12mo`


---




## ğŸ§° Tech Stack

- **Compute**: PySpark 3.x, Docker
- **ETL**: Python, dbt
- **DB**: DuckDB
- **ML**: XGBoost
- **Tracking**: MLflow
- **Data**: NYC TLC, Open-Meteo Archive API
- **Orchestration**: Dagster *(optional, not required for pandas version)*

---



---

Built by [@duytruong1211](https://github.com/duytruong1211) 

