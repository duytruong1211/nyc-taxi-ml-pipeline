

# ğŸ—½ NYC Taxi ML Pipeline

A full-stack machine learning pipeline to predict NYC taxi trip duration.

**Designed for:** clarity, reproducibility, and real-world ML infra readiness â€” with lean setup for cloning.

---

## ğŸ§­ Project Evolution

> **Prototyped in Spark. Delivered in pandas.**

The project began with a full **Spark-based workflow** for processing large-scale NYC TLC data, using:

- ğŸ”¹ Spark for prototyping data transformations and rolling aggregations  
- ğŸ”¹ dbt for SQL-style modeling  
- ğŸ”¹ Dagster for orchestration (optional)

However, for simplicity, speed, and **ease of cloning**, we **ported the full pipeline to Python + pandas**.

### âœ… Why pandas for final version?

- âš¡ Lightweight: no Spark setup or cluster needed
- ğŸ’» Local-friendly: works out-of-the-box via `python main.py`
- ğŸ” Same logic: All Spark SQL logic reimplemented using pandas
- ğŸ“¦ Portable: Easy to fork, run, and adapt


Both versions are maintained:

- **`/spark_full/`** folder â€” full Spark/dbt version
- **Root folder** â€” lean pandas version for reproducibility and demo


## ğŸš€ Quickstart

> ğŸ“Œ **Recommended Python version**: 3.10

Set up and run the full pipeline locally with no cluster needed ( Recommended for Mac User)

```bash
# 1. Create virtual environment
python3.10 -m venv nyc_taxi
source nyc_taxi/bin/activate  

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run test mode (quick demo)
python main.py --mode= est
# âœ… Ingest Janâ€“Apr 2024
# âœ… Train model for April 2024
# âœ… Good for validating setup + MLflow run

# 4. Run full pipeline (bulk mode)
python main.py --mode bulk
# âœ… Process all 2023â€“2024 data
# âœ… Build rolling features
# âœ… Train + log monthly models

# 5. Ingest new data (incremental)
python main.py --mode incremental --year 2025 --month 1
# âœ… Add new month (e.g. Jan 2025)
# âœ… Update features + retrain model

# 6. Launch MLflow dashboard
mlflow ui
# â†’ http://localhost:5000

```
---

## ğŸ“‚ Project Structure

```text
nyc-taxi-ml-pipeline/
â”œâ”€â”€ data/                # Data snapshots (bronze/silver/gold)
â”œâ”€â”€ models/              # Saved XGBoost models
â”œâ”€â”€ notebooks/           # EDA + diagnostics
â”œâ”€â”€ pipeline/            # Data ingestion and transformation scripts
â”œâ”€â”€ weather/             # Open-Meteo ingestion and precompute logic
â”œâ”€â”€ main.py              # Pipeline entry point
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ğŸ” Model Overview

After running the pipeline, launch MLflow UI:

```bash
mlflow ui
```
You will see a dashboard like this
![MLflow Dashboard](utils/mlflow_output.png)


---

## ğŸ§± Feature Store Summary

- **Temporal**  
  `pickup_hour`, `is_rush_hour_morning`, `is_weekend`

- **Calendar**  
  `is_holiday`, `is_near_holiday`, `is_payroll_window`

- **Zone & Ride Info**  
  `is_same_zone`, `is_airport_pu_trip`, `passenger_count`

- **Weather** *(by borough & hour)*  
  `temperature`, `precipitation`, `cloudcover`

- **Rolling Aggregates** *(PU-DO pairs)*  
  `avg_duration_min_3mo`, `avg_fare_12mo`, `trip_count_12mo`


---


## ğŸ“˜ Reports

- ğŸ—’ï¸ [Notion Summary Report](https://bitter-aster-788.notion.site/NYC-Taxi-ETA-Forecasting-Modeling-Meets-Real-World-Chaos-2248b64123bf805991cae210535ab3c7) *(stakeholder view â€“ business insights)*
- ğŸ““ [Notebook Spark Walkthrough](spark_full/spark_eta_model.ipynb) *(Spark ML version â€“ deep dive)*


---

## ğŸ§° Tech Stack

- **Compute**: PySpark 3.x, Docker
- **ETL**: Python, dbt
- **ML**: XGBoost, scikit-learn
- **Tracking**: MLflow
- **Data**: NYC TLC, Open-Meteo Archive API
- **Orchestration**: Dagster *(optional, not required for pandas version)*

---



---

Built by [@duytruong1211](https://github.com/duytruong1211) â€” tailored for clarity, portability, and real-world data science workflow.

